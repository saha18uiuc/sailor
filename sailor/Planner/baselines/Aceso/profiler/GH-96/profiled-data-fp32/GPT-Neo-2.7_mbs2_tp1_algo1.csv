op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,236.356,1956.427,0.031,40.000,1272.500,50.000,0.000,1254.000
enc-1st-layernorm,39.190,119.108,40.000,80.000,0.000,40.031,0.000,160.000
enc-attention-qkv,663.757,501.752,80.000,160.000,75.000,120.000,0.000,0.000
enc-attention-score,458.354,759.596,160.000,1104.000,0.000,1024.000,1024.000,120.000
enc-attention-softmax,2993.321,4095.900,1104.000,1104.000,0.000,1024.000,1024.000,2048.000
enc-attention-dropout,812.137,661.576,1104.000,1104.000,0.000,1280.000,0.000,2048.000
enc-attention-context,392.193,888.556,1104.000,80.000,0.000,40.000,40.000,1064.000
enc-attention-dense,171.673,211.042,80.000,80.010,25.000,40.000,0.000,0.000
enc-post-attention-dropout,113.285,72.342,80.010,40.000,0.000,50.000,40.000,160.000
enc-2nd-layernorm,39.393,120.205,40.000,80.000,0.000,40.031,0.000,160.000
enc-MLP-GEMM-1,759.131,727.606,80.000,200.039,100.000,160.000,0.000,0.000
enc-MLP-gelu,110.126,204.456,200.039,200.000,0.000,160.000,0.000,456.000
enc-MLP-GEMM-2,732.523,832.170,200.000,80.010,100.000,40.000,0.000,0.000
enc-post-MLP-dropout,120.604,71.043,80.010,40.000,0.000,50.000,40.000,160.000
final-layernorm,83.774,391.823,40.000,40.000,0.000,80.031,0.000,80.000
gpt-post-process,12439.662,8852.214,40.000,0.000,1252.500,2004.051,0.000,0.000
