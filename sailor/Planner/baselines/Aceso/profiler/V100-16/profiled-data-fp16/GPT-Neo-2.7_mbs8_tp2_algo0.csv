op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,3572.583,4282.182,0.062,80.000,323.125,120.141,239.859,810.000
enc-1st-layernorm,282.210,1086.408,80.000,160.000,0.000,80.125,0.000,640.000
enc-attention-qkv,4203.808,5678.272,160.000,200.000,18.750,120.000,80.000,440.000
enc-attention-score,2500.349,3825.855,200.000,1144.000,0.000,1024.000,1024.000,2168.000
enc-attention-softmax,2333.373,2993.208,1144.000,1144.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,3823.078,3229.046,1144.000,1144.000,0.000,1536.000,0.000,4096.000
enc-attention-context,2307.111,4308.611,1144.000,120.000,0.000,40.000,40.000,1144.000
enc-attention-dense,2863.055,1055.169,120.000,160.005,6.250,80.000,0.000,280.000
enc-post-attention-dropout,891.811,466.156,160.005,80.000,0.000,120.000,80.000,400.000
enc-2nd-layernorm,260.884,1018.345,80.000,160.000,0.000,80.125,0.000,640.000
enc-MLP-GEMM-1,4840.517,5980.110,160.000,240.010,25.000,160.000,0.000,560.000
enc-MLP-gelu,440.019,818.610,240.010,240.000,0.000,160.000,0.000,720.000
enc-MLP-GEMM-2,6073.105,4122.144,240.000,160.005,25.000,80.000,0.000,400.000
enc-post-MLP-dropout,837.499,469.035,160.005,80.000,0.000,120.000,80.000,400.000
final-layernorm,518.370,705.230,80.000,80.000,0.000,160.125,0.000,320.000
gpt-post-process,102103.674,76570.654,80.000,0.000,313.125,4008.203,2003.797,0.000
